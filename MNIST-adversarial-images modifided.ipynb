{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies for entire notebook here\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "import numpy as np\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "from art.attacks.fast_gradient import FastGradientMethod\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions for creating weights and biases\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "def weight_variable(shape, name=None):    \n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "# Functions for convolution and pooling functions\n",
    "def conv2d(x, W, name=None):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME', name=name)\n",
    "\n",
    "def max_pooling_2x2(x, name=None):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alonh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "def load_saved_adversarial():    \n",
    "    local_path = \"C:\\\\Users\\\\alonh\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\\"\n",
    "    # original_number = np.load(local_path + \"original_number.npy\")\n",
    "    # target_number = np.load(local_path + \"target_number.npy\")\n",
    "    # prob_list = np.load(local_path + \"prob_list.npy\")\n",
    "    adv_img_list = np.load(local_path + \"adv_img_list.npy\")\n",
    "    return adv_img_list\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#load_adversarial\n",
    "# original_number, target_number, prob_list, adv_img_list = load_saved_adversarial()\n",
    "adv_img_list = load_saved_adversarial()\n",
    "print(adv_img_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alonh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n(20000, 784)\n<class 'numpy.ndarray'>\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# uniting and shuffeling between adv inputs and benign\n",
    "# # creating [0, 1] labels for adv\n",
    "number_of_adv_images = adv_img_list.shape[0]\n",
    "adv_label = np.zeros(number_of_adv_images)\n",
    "adv_label = np.c_[adv_label, np.ones(number_of_adv_images)]\n",
    "\n",
    "# creating [1,0] labels for benign\n",
    "number_of_benign = 20000\n",
    "benign_label = np.ones(number_of_benign)\n",
    "benign_label = np.c_[benign_label, np.zeros(number_of_benign)]\n",
    "# uniting adv and benign\n",
    "united_labels = np.concatenate((adv_label, benign_label))\n",
    "\n",
    "reshaped_benign = mnist.train.images[0:number_of_benign]\n",
    "adv_img_list = np.reshape(adv_img_list, newshape=(-1, 784))\n",
    "print(adv_img_list.shape)\n",
    "print(reshaped_benign.shape)\n",
    "print(type(adv_img_list))\n",
    "print(type(reshaped_benign))\n",
    "united_images = np.concatenate((adv_img_list, reshaped_benign), axis=0)\n",
    "united_images_and_labels = np.c_[united_images, united_labels]\n",
    "np.random.shuffle(united_images_and_labels)\n",
    "#add precondition\n",
    "images_data, labels_data = np.hsplit(united_images_and_labels, [united_images_and_labels.shape[1]-2])\n",
    "train_test_rate = 0.9\n",
    "train_size = int(images_data.shape[0]*train_test_rate)\n",
    "image_train_data, image_test_data = np.split(images_data, [train_size])\n",
    "label_train_data, label_test_data = np.split(labels_data, [train_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alonh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# should start run from here\n",
    "yaml_file = open('C:\\\\Users\\\\alonh\\\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"C:\\\\Users\\\\alonh\\\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\model.h5\")\n",
    "\n",
    "\n",
    "conv1 = loaded_model.layers[0].get_weights()\n",
    "conv2 = loaded_model.layers[1].get_weights()\n",
    "\n",
    "W_conv1 = conv1[0]\n",
    "b_conv1 = conv1[1]\n",
    "\n",
    "W_conv2 = conv2[0]\n",
    "b_conv2 = conv2[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholders nodes for images and label inputs\n",
    "# Create placeholders nodes for images and label inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='xDetector')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 2], name='yDetector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified nn based on original\n",
    "# Input layer\n",
    "x_image_new = tf.reshape(x, [-1,28,28,1]) # mnist image comes in as 784 vector\n",
    "\n",
    "# # Conv layer 1 - 32x5x5 - using same weights and biases as the pretrained\n",
    "# W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "# b_conv1 = bias_variable([32])\n",
    "x_conv1 = tf.nn.relu(conv2d(x_image_new, W_conv1) + b_conv1, name=\"x_conv1_new\")\n",
    "x_pool1 = max_pooling_2x2(x_conv1, name=\"x_pool1_new\")\n",
    "# Conv detector layer 1  - 32x5x5\n",
    "W_conv1_detector = weight_variable([5, 5, 32, 32], name=\"W_conv1_detector\")\n",
    "b_conv1_detector = bias_variable([32], name=\"b_conv1_detector\")\n",
    "x_conv1_detector = tf.nn.relu(conv2d(x_pool1, W_conv1_detector) + b_conv1_detector, name=\"x_conv1_detector\")\n",
    "x_pool1_detector = max_pooling_2x2(x_conv1_detector, name=\"x_pool1_detector\")\n",
    "\n",
    "# # Conv layer 2 - 64x5x5\n",
    "# W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "# b_conv2 = bias_variable([64])\n",
    "x_conv2 = tf.nn.relu(conv2d(x_pool1, W_conv2) + b_conv2, name=\"x_conv2_new\")\n",
    "x_pool2 = max_pooling_2x2(x_conv2, name=\"x_pool2_new\")\n",
    "\n",
    "# stacking conv2 output and x_pool1 detector output\n",
    "conv_detector_2_input = tf.concat([x_conv2, x_pool1], 3)\n",
    "\n",
    "\n",
    "# Conv detector layer 2 - 64x5x5\n",
    "W_conv2_detector = weight_variable([5, 5, 96, 64], name=\"W_conv2_detector\")\n",
    "b_conv2_detector = bias_variable([64], name=\"b_conv2_detector\")\n",
    "x_conv2_detector = tf.nn.relu(conv2d(conv_detector_2_input, W_conv2_detector) + b_conv2_detector, name=\"x_conv2_detector\")\n",
    "x_pool2_detector = max_pooling_2x2(x_conv2_detector, name=\"x_pool2_detector\")\n",
    "# Flatten - keras 'flatten'\n",
    "pool_shape = x_pool2_detector.shape\n",
    "shape_size = (pool_shape[1]*pool_shape[2]*pool_shape[3]).value\n",
    "x_flat_detector = tf.reshape(x_pool2_detector, [-1, shape_size], name=\"x_flat_detector\")\n",
    "\n",
    "\n",
    "W_fc1_detector = weight_variable([shape_size, 1024], name=\"W_fc1_detector\") # max pooling reduced image to 7x7\n",
    "b_fc1_detector = bias_variable([1024], name=\"b_fc1_detector\")\n",
    "x_fc1_detector = tf.nn.relu(tf.matmul(x_flat_detector, W_fc1_detector) + b_fc1_detector, name=\"x_fc1_detector\")\n",
    "\n",
    "# Regularization with dropout\n",
    "keep_prob_detector = tf.placeholder(tf.float32, name=\"keep_prob_detector\")\n",
    "x_fc1_drop_detector = tf.nn.dropout(x_fc1_detector, keep_prob_detector, name=\"x_fc1_drop_detector\")\n",
    "\n",
    "\n",
    "# Classification layer\n",
    "W_fc2_detector = weight_variable([1024, 2], name=\"W_fc2_detector\")\n",
    "b_fc2_detector = bias_variable([2], name=\"b_fc2_detector\")\n",
    "y_conv= tf.matmul(x_fc1_drop_detector, W_fc2_detector) + b_fc2_detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(?, 14, 14, 96), dtype=float32)\n3136\nTensor(\"x_conv1_new:0\", shape=(?, 28, 28, 32), dtype=float32)\nTensor(\"x_pool1_new:0\", shape=(?, 14, 14, 32), dtype=float32)\nTensor(\"x_conv1_detector:0\", shape=(?, 14, 14, 32), dtype=float32)\nTensor(\"x_conv2_new:0\", shape=(?, 14, 14, 64), dtype=float32)\nTensor(\"concat:0\", shape=(?, 14, 14, 96), dtype=float32)\nTensor(\"x_conv2_detector:0\", shape=(?, 14, 14, 64), dtype=float32)\nTensor(\"x_pool2_detector:0\", shape=(?, 7, 7, 64), dtype=float32)\nTensor(\"x_flat_detector:0\", shape=(?, 3136), dtype=float32)\nTensor(\"x_fc1_detector:0\", shape=(?, 1024), dtype=float32)\nTensor(\"add_5:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(conv_detector_2_input)\n",
    "print(shape_size)\n",
    "print(x_conv1)\n",
    "\n",
    "print(x_pool1)\n",
    "print(x_conv1_detector)\n",
    "print(x_conv2)\n",
    "print(conv_detector_2_input)\n",
    "print(x_conv2_detector)\n",
    "print(x_pool2_detector)\n",
    "print(x_flat_detector)\n",
    "print(x_fc1_detector)\n",
    "print(y_conv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities - output from model (not the same as logits)\n",
    "# CHANGE!!-----------------------------------------------------------------\n",
    "y = tf.nn.softmax(y_conv, name=\"y_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv), name=\"cross_entropy2\")\n",
    "# add variables to optimize here:\n",
    "var_list = [W_conv1_detector, W_conv2_detector, W_fc2_detector, b_conv1_detector, b_conv2_detector, b_fc2_detector]\n",
    "train_step2 = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy2, var_list=var_list, name=\"train_step2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup to test accuracy of model\n",
    "correct_prediction2 = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1), name=\"correct_prediction2\")\n",
    "accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32), name=\"accuracy2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_uninitialized_global_variables(sess):\n",
    "    \"\"\"\n",
    "    Only initializes the variables of a TensorFlow session that were not\n",
    "    already initialized.\n",
    "    :param sess: the TensorFlow session\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # List all global variables\n",
    "    global_vars = tf.global_variables()\n",
    "\n",
    "    # Find initialized status for all variables\n",
    "    is_var_init = [tf.is_variable_initialized(var) for var in global_vars]\n",
    "    is_initialized = sess.run(is_var_init)\n",
    "\n",
    "    # List all variables that were not initialized previously\n",
    "    not_initialized_vars = [var for (var, init) in\n",
    "                            zip(global_vars, is_initialized) if not init]\n",
    "    # for uninit in not_initialized_vars:\n",
    "    #     print(uninit)\n",
    "    # Initialize all uninitialized variables found, if any\n",
    "    if len(not_initialized_vars):        \n",
    "        sess.run(tf.variables_initializer(not_initialized_vars)) \n",
    "\n",
    "initialize_uninitialized_global_variables(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.53125\nstep 2, training accuracy 0.585938\nstep 4, training accuracy 0.632812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6, training accuracy 0.6875\nstep 8, training accuracy 0.609375\nstep 10, training accuracy 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12, training accuracy 0.710938\nstep 14, training accuracy 0.671875\nstep 16, training accuracy 0.679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18, training accuracy 0.578125\nstep 20, training accuracy 0.632812\nstep 22, training accuracy 0.609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24, training accuracy 0.640625\nstep 26, training accuracy 0.585938\nstep 28, training accuracy 0.640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30, training accuracy 0.6875\nstep 32, training accuracy 0.59375\nstep 34, training accuracy 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36, training accuracy 0.625\nstep 38, training accuracy 0.625\nstep 40, training accuracy 0.710938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42, training accuracy 0.703125\nstep 44, training accuracy 0.742188\nstep 46, training accuracy 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48, training accuracy 0.664062\nstep 50, training accuracy 0.726562\nstep 52, training accuracy 0.664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54, training accuracy 0.671875\nstep 56, training accuracy 0.671875\nstep 58, training accuracy 0.773438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60, training accuracy 0.757812\nstep 62, training accuracy 0.679688\nstep 64, training accuracy 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 66, training accuracy 0.679688\nstep 68, training accuracy 0.695312\nstep 70, training accuracy 0.703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 72, training accuracy 0.8125\nstep 74, training accuracy 0.703125\nstep 76, training accuracy 0.726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 78, training accuracy 0.664062\nstep 80, training accuracy 0.671875\nstep 82, training accuracy 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 84, training accuracy 0.6875\nstep 86, training accuracy 0.726562\nstep 88, training accuracy 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 90, training accuracy 0.742188\nstep 92, training accuracy 0.742188\nstep 94, training accuracy 0.695312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 96, training accuracy 0.742188\nstep 98, training accuracy 0.71875\nstep 100, training accuracy 0.742188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 102, training accuracy 0.679688\nstep 104, training accuracy 0.796875\nstep 106, training accuracy 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 108, training accuracy 0.71875\nstep 110, training accuracy 0.625\nstep 112, training accuracy 0.710938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 114, training accuracy 0.703125\nstep 116, training accuracy 0.757812\nstep 118, training accuracy 0.679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 120, training accuracy 0.765625\nstep 122, training accuracy 0.757812\nstep 124, training accuracy 0.757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 126, training accuracy 0.75\nstep 128, training accuracy 0.789062\nstep 130, training accuracy 0.789062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 132, training accuracy 0.789062\nstep 134, training accuracy 0.820312\nstep 136, training accuracy 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 138, training accuracy 0.789062\nstep 140, training accuracy 0.773438\nstep 142, training accuracy 0.773438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 144, training accuracy 0.757812\nstep 146, training accuracy 0.757812\nstep 148, training accuracy 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 150, training accuracy 0.789062\nstep 152, training accuracy 0.789062\nstep 154, training accuracy 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 156, training accuracy 0.851562\nstep 158, training accuracy 0.8125\nstep 160, training accuracy 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 162, training accuracy 0.867188\nstep 164, training accuracy 0.820312\nstep 166, training accuracy 0.820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 168, training accuracy 0.890625\nstep 170, training accuracy 0.820312\nstep 172, training accuracy 0.804688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 174, training accuracy 0.84375\nstep 176, training accuracy 0.804688\nstep 178, training accuracy 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 180, training accuracy 0.84375\nstep 182, training accuracy 0.90625\nstep 184, training accuracy 0.835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 186, training accuracy 0.851562\nstep 188, training accuracy 0.835938\nstep 190, training accuracy 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 192, training accuracy 0.828125\nstep 194, training accuracy 0.796875\nstep 196, training accuracy 0.820312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 198, training accuracy 0.867188\nstep 200, training accuracy 0.859375\nstep 202, training accuracy 0.914062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 204, training accuracy 0.9375\nstep 206, training accuracy 0.9375\nstep 208, training accuracy 0.921875\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# Run once to get the model to a good confidence level\n",
    "batch_size = 128\n",
    "batch_index = 0\n",
    "image_train_size = image_train_data.shape[0]\n",
    "number_of_steps = int(image_train_size / batch_size)\n",
    "for i in range(number_of_steps):\n",
    "    # if(batch_index>=image_train_data.shape[0]):\n",
    "    #     print(\"reached limit of train data current index: \", batch_index, \"data size: \", image_train_data.shape[0])\n",
    "    #     break\n",
    "    batch_image = image_train_data[batch_index: (batch_index + batch_size)]\n",
    "    batch_label = label_train_data[batch_index: (batch_index + batch_size)]\n",
    "    if i % 2 == 0:\n",
    "        train_accuracy = accuracy2.eval(session=sess, feed_dict={x: batch_image, y_:batch_label, keep_prob_detector: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train_step2.run(feed_dict={x: batch_image, y_: batch_label, keep_prob_detector: 0.4})\n",
    "    batch_index = batch_index + batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.926\n"
     ]
    }
   ],
   "source": [
    "# Run trained model against test data\n",
    "print(\"test accuracy %g\"%accuracy2.eval(session=sess, feed_dict={x: image_test_data, \n",
    "                                                  y_: label_test_data, keep_prob_detector: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
