{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies for entire notebook here\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run nicely in jupyter notebook\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for creating weights and biases\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "def weight_variable(shape, name=None):    \n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "# Functions for convolution and pooling functions\n",
    "def conv2d(x, W, name=None):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME', name=name)\n",
    "\n",
    "def max_pooling_2x2(x, name=None):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholders nodes for images and label inputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='xOriginal')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10], name='yOriginal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = (Wx +b)\n",
    "# https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "# Input layer\n",
    "x_image = tf.reshape(x, [-1,28,28,1]) # mnist image comes in as 784 vector\n",
    "\n",
    "# Conv layer 1 - 32x5x5\n",
    "W_conv1 = weight_variable([5, 5, 1, 32], name=\"W_conv1\")\n",
    "b_conv1 = bias_variable([32], name=\"b_conv1\")\n",
    "x_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name=\"x_conv1\")\n",
    "x_pool1 = max_pooling_2x2(x_conv1, name=\"x_pool1\")\n",
    "\n",
    "# Conv layer 2 - 64x5x5\n",
    "W_conv2 = weight_variable([5, 5, 32, 64], name=\"W_conv2\")\n",
    "b_conv2 = bias_variable([64], name=\"b_conv2\")\n",
    "x_conv2 = tf.nn.relu(conv2d(x_pool1, W_conv2) + b_conv2, name=\"x_conv2\")\n",
    "x_pool2 = max_pooling_2x2(x_conv2, name=\"x_pool2\")\n",
    "\n",
    "# Flatten - keras 'flatten'\n",
    "x_flat = tf.reshape(x_pool2, [-1, 7*7*64], name=\"x_flat\")\n",
    "\n",
    "# Dense fully connected layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024], name=\"W_fc1\") # max pooling reduced image to 7x7\n",
    "b_fc1 = bias_variable([1024], name=\"b_fc1\")\n",
    "x_fc1 = tf.nn.relu(tf.matmul(x_flat, W_fc1) + b_fc1, name=\"x_fc1\")\n",
    "\n",
    "# Regularization with dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_fc1_drop = tf.nn.dropout(x_fc1, keep_prob)\n",
    "\n",
    "# Classification layer\n",
    "W_fc2 = weight_variable([1024, 10], name=\"W_fc2\")\n",
    "b_fc2 = bias_variable([10], name=\"b_fc2\")\n",
    "y_conv = tf.matmul(x_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities - output from model (not the same as logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup to test accuracy of model\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize all global variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Run once to get the model to a good confidence level\n",
    "# was 1000\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run trained model against test data\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images[0:500], \n",
    "                                                  y_: mnist.test.labels[0:500], keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(image_list, output_probs=False, adversarial=False):\n",
    "    '''\n",
    "    Evaluate images against trained model and plot images.\n",
    "    If adversarial == True, replace middle image title appropriately\n",
    "    Return probability list if output_probs == True\n",
    "    '''\n",
    "    prob = y.eval(feed_dict={x: image_list, keep_prob: 1.0})\n",
    "    \n",
    "    pred_list = np.zeros(len(image_list)).astype(int)\n",
    "    pct_list = np.zeros(len(image_list)).astype(int)\n",
    "    \n",
    "    # Setup image grid\n",
    "    import math\n",
    "    cols = 3\n",
    "    rows = math.ceil(image_list.shape[0]/cols)\n",
    "    fig = plt.figure(1, (12., 12.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(rows, cols),  # creates grid of axes\n",
    "                     axes_pad=0.5,  # pad between axes in inch.\n",
    "                     )\n",
    "    \n",
    "    # Get probs, images and populate grid\n",
    "    for i in range(len(prob)):\n",
    "        pred_list[i] = np.argmax(prob[i]) # for mnist index == classification\n",
    "        pct_list[i] = prob[i][pred_list[i]] * 100\n",
    "\n",
    "        image = image_list[i].reshape(28,28)\n",
    "        grid[i].imshow(image)\n",
    "        \n",
    "        grid[i].set_title('Label: {0} \\nCertainty: {1}%' \\\n",
    "                          .format(pred_list[i], \n",
    "                                  pct_list[i]))\n",
    "        \n",
    "        # Only use when plotting original, partial deriv and adversarial images\n",
    "        if (adversarial) & (i % 3 == 1): \n",
    "            grid[i].set_title(\"Adversarial \\nPartial Derivatives\")\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return prob if output_probs else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 2s [:,2] from top 500 [0:500], nonzero returns tuple, get index[0], then first 10 [0:10]\n",
    "index_of_2s = np.nonzero(mnist.test.labels[0:500][:,2])[0][0:10]\n",
    "x_batch = mnist.test.images[index_of_2s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly inspired by:\n",
    "# https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture\n",
    "def create_plot_adversarial_images(x_image, y_label, lr=0.1, n_steps=1, output_probs=False):\n",
    "    \n",
    "    original_image = x_image\n",
    "    probs_per_step = []\n",
    "    \n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/train/gradient_computation\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    deriv = tf.gradients(loss, x)\n",
    "    image_adv = tf.stop_gradient(x - tf.sign(deriv)*lr/n_steps)\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) # prevents -ve values creating 'real' image\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        # Calculate derivative and adversarial image\n",
    "        dydx = sess.run(deriv, {x: x_image, keep_prob: 1.0}) # can't seem to access 'deriv' w/o running this\n",
    "        x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "        \n",
    "        # Create darray of 3 images - orig, noise/delta, adversarial\n",
    "        x_image = np.reshape(x_adv, (1, 784))\n",
    "        img_adv_list = original_image\n",
    "        img_adv_list = np.append(img_adv_list, dydx[0], axis=0)\n",
    "        img_adv_list = np.append(img_adv_list, x_image, axis=0)\n",
    "\n",
    "        # Print/plot images and return probabilities\n",
    "        probs = plot_predictions(img_adv_list, output_probs=output_probs, adversarial=True)\n",
    "        probs_per_step.append(probs) if output_probs else None\n",
    "    \n",
    "    return probs_per_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions(image_list):\n",
    "    prob = y.eval(feed_dict={x: image_list, keep_prob: 1.0})\n",
    "    \n",
    "    pct_list = np.zeros(len(image_list))\n",
    "    pred_list = np.argmax(prob, axis=1)\n",
    "    for i in range(len(prob)):\n",
    "        pct_list[i] = prob[i][pred_list[i]]\n",
    "        \n",
    "    return pred_list, pct_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adversarial_image(x_image, y_label, lr=0.1, n_steps=1):\n",
    "    \n",
    "    original_image = x_image\n",
    "    probs_per_step = []\n",
    "    \n",
    "    # Calculate loss, derivative and create adversarial image\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/train/gradient_computation\n",
    "    loss =  tf.nn.softmax_cross_entropy_with_logits(labels=y_label, logits=y_conv)\n",
    "    deriv = tf.gradients(loss, x)\n",
    "    image_adv = tf.stop_gradient(x - tf.sign(deriv)*lr/n_steps)\n",
    "    image_adv = tf.clip_by_value(image_adv, 0, 1) # prevents -ve values creating 'real' image\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # Calculate derivative and adversarial image\n",
    "        dydx = sess.run(deriv, {x: x_image, keep_prob: 1.0}) # can't seem to access 'deriv' w/o running this\n",
    "        x_adv = sess.run(image_adv, {x: x_image, keep_prob: 1.0})\n",
    "        x_image = np.reshape(x_adv, (1, 784))\n",
    "        \n",
    "    label, prob = create_predictions(x_image)\n",
    "    return x_image, label, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pick a random 2 image from first 1000 images \n",
    "# # Create adversarial image and with target label 6\n",
    "# index_of_2s = np.nonzero(mnist.test.labels[0:1000][:,2])[0]\n",
    "# rand_index = np.random.randint(0, len(index_of_2s))\n",
    "# image_norm = mnist.test.images[index_of_2s[rand_index]]\n",
    "# image_norm = np.reshape(image_norm, (1, 784))\n",
    "# label_adv = [0,0,0,0,0,0,1,0,0,0] # one hot encoded, adversarial label 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_specific_adversarial_image(originNumber, destinationNumber, n_steps=10):\n",
    "    index_of_number = np.nonzero(mnist.test.labels[0:1000][:,originNumber])[0]\n",
    "    rand_index = np.random.randint(0, len(index_of_number))\n",
    "    image_norm = mnist.test.images[index_of_number[rand_index]]\n",
    "    image_norm = np.reshape(image_norm, (1, 784))    \n",
    "    label_adv = np.zeros(10).astype(int) # one hot encoded\n",
    "    label_adv[destinationNumber] = 1;\n",
    "    adv_image, label, prob = create_adversarial_image(image_norm, label_adv, lr=0.2, n_steps=n_steps)\n",
    "    return adv_image, label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trainSet():\n",
    "    number_of_examples_per_number = 10;\n",
    "    original_number = np.zeros(shape=(1, 1))\n",
    "    original_number = np.delete(original_number, 0, 0)\n",
    "    target_number = np.zeros(shape=(1, 10))\n",
    "    target_number = np.delete(target_number, 0, 0)\n",
    "    prob_list = np.zeros(shape=(1, 1))\n",
    "    prob_list = np.delete(prob_list, 0, 0)\n",
    "    adv_img_list = np.zeros(shape=(1, 784))\n",
    "    adv_img_list = np.delete(adv_img_list, 0, 0)\n",
    "    for origin in range(10):\n",
    "        for p in range(number_of_examples_per_number):\n",
    "            for target in range(10):\n",
    "                if origin != target:\n",
    "                    prob = 0\n",
    "                    label = origin\n",
    "                    n_steps = 10\n",
    "                    while prob < 0.9 or label != target:\n",
    "                        adv_image, label, prob = create_specific_adversarial_image(origin, target, n_steps)\n",
    "                        prob = prob[0]\n",
    "                        label = label[0]\n",
    "                        print(\"-\", end=\"\", flush=True)\n",
    "                        \n",
    "                        #print((origin, target, label, prob, n_steps), end=\"\", flush=True)                        \n",
    "                        #print(\" X \")\n",
    "                        n_steps = n_steps + 2\n",
    "                    original_number = np.append(original_number, origin)\n",
    "                    target_to_add = np.zeros(shape=(1,10))\n",
    "                    target_to_add[0][target] = 1 #to vectorize the labeling\n",
    "                    target_number = np.concatenate((target_number, target_to_add), axis=0)\n",
    "                    prob_list = np.append(prob_list, prob)\n",
    "                    #the action of concation can be i,proved\n",
    "                    adv_img_list = np.concatenate((adv_img_list, adv_image), axis=0)\n",
    "                    print(\"|\", end=\"\", flush=True)\n",
    "        print(\"Number\")            \n",
    "        #print(original_number, target_number, prob_list)\n",
    "    return original_number, target_number, prob_list, adv_img_list\n",
    "\n",
    "\n",
    "def generate_adversarial_and_save():\n",
    "    local_path = \"C:\\\\Users\\\\alonh\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\\"\n",
    "    original_number, target_number, prob_list, adv_img_list = generate_trainSet()\n",
    "    np.save(local_path + \"original_number.npy\", original_number)\n",
    "    np.save(local_path + \"target_number.npy\", target_number)\n",
    "    np.save(local_path + \"prob_list.npy\", prob_list)\n",
    "    np.save(local_path + \"adv_img_list.npy\", adv_img_list)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_saved_adversarial():    \n",
    "    local_path = \"C:\\\\Users\\\\alonh\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\\"\n",
    "    original_number = np.load(local_path + \"original_number.npy\")\n",
    "    target_number = np.load(local_path + \"target_number.npy\")\n",
    "    prob_list = np.load(local_path + \"prob_list.npy\")\n",
    "    adv_img_list = np.load(local_path + \"adv_img_list.npy\")\n",
    "    return original_number, target_number, prob_list, adv_img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_adversarial_and_save()\n",
    "original_number, target_number, prob_list, adv_img_list = load_saved_adversarial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniting and shuffeling between adv inputs and benign\n",
    "# creating labels as 2d array which [0,1] is adv\n",
    "number_of_adv_images = adv_img_list.shape[0]\n",
    "adv_label = np.zeros(number_of_adv_images)\n",
    "adv_label = np.c_[adv_label, np.ones(number_of_adv_images)]\n",
    "\n",
    "number_of_benign = 1000\n",
    "benign_label = np.ones(number_of_benign)\n",
    "benign_label = np.c_[benign_label, np.zeros(number_of_benign)]\n",
    "# uniting adv and benign\n",
    "united_labels = np.concatenate((adv_label, benign_label), axis=0)\n",
    "united_images = np.concatenate((adv_img_list, mnist.train.images[0:number_of_benign]), axis=0)\n",
    "united_images_and_labels = np.c_[united_images, united_labels]\n",
    "np.random.shuffle(united_images_and_labels)\n",
    "#add precondition\n",
    "images_data, labels_data = np.hsplit(united_images_and_labels, [united_images_and_labels.shape[1]-2])\n",
    "train_size = 700\n",
    "image_train_data, image_test_data = np.split(images_data, [train_size])\n",
    "label_train_data, label_test_data = np.split(labels_data, [train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset and restore old variables\n",
    "local_path = \"C:\\\\Users\\\\alonh\\Documents\\\\Thesis\\\\MNIST-adversarial-images\\\\original-nn-data.ckpt\"\n",
    "# Initilize all global variables\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, local_path)\n",
    "saver = None\n",
    "tf.reset_default_graph()\n",
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
